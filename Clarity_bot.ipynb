{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Этот код принимает на вход текст в формате txt и выдает следующие метрики: оценка удобочитаемости нейросетевой моделью, оценка удобочитаемости по классическому автоматизированному индексу (на основе средней длины слов и предложений), 44 лингвистические характеристики текста, значимые для принятия решения об удобочитаемости. \n",
    "\n",
    "#Среда Python 3.7.9 64-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\379\\sklearn\\base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Семейный\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e02e3a386541289df87e75bc23a8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 16:39:37 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2022-11-24 16:39:39 INFO: File exists: C:\\Users\\Семейный\\stanza_resources\\ru\\default.zip.\n",
      "2022-11-24 16:39:44 INFO: Finished downloading models and saved to C:\\Users\\Семейный\\stanza_resources.\n",
      "2022-11-24 16:39:44 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "| lemma     | syntagrus |\n",
      "| depparse  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2022-11-24 16:39:44 INFO: Use device: cpu\n",
      "2022-11-24 16:39:44 INFO: Loading: tokenize\n",
      "2022-11-24 16:39:45 INFO: Loading: pos\n",
      "2022-11-24 16:39:45 INFO: Loading: lemma\n",
      "2022-11-24 16:39:45 INFO: Loading: depparse\n",
      "2022-11-24 16:39:46 INFO: Loading: ner\n",
      "2022-11-24 16:39:48 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "#необходимые библиотеки\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, MaxPooling1D, Conv1D, GlobalMaxPooling1D, Dropout, LSTM, GRU, SpatialDropout1D, Concatenate\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score\n",
    "import pandas as pd\n",
    "import keras\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import io \n",
    "from tensorflow.python.keras.preprocessing.text import tokenizer_from_json\n",
    "import joblib\n",
    "ss=joblib.load('std_scaler.bin')\n",
    "import textstat\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os.path\n",
    "import sys\n",
    "import shelve\n",
    "import itertools\n",
    "import spacy\n",
    "import stanza\n",
    "stanza.download('ru')\n",
    "nlp2 = stanza.Pipeline('ru') \n",
    "from spacy.lang.ru.examples import sentences \n",
    "nlp = spacy.load('ru_core_news_lg') #словарь \n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "import string\n",
    "from string import digits\n",
    "import ruts\n",
    "from ruts import BasicStats\n",
    "from ruts import DiversityStats\n",
    "import statistics \n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\379\\ipykernel_launcher.py:18: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "D:\\Python\\379\\ipykernel_launcher.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "D:\\Python\\379\\ipykernel_launcher.py:29: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "D:\\Python\\379\\ipykernel_launcher.py:30: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "D:\\Python\\379\\ipykernel_launcher.py:31: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "#Необходимые словари\n",
    "\n",
    "A1 = ('а','август','автобус','автор','администрация','адрес','активный','алло','английский','англичанин','англичане','англичанка','англо-русский','испанско-русский','китайско-русский','немецко-русский','французско-русский','анкета','апельсин','аппетит','апрель','аптека','артист','артистка','архитектор','архитектура','аспирант','аспирантка','апсирантура','аудитория','аэропорт','бабушка','багаж','балет','банк','баскетбол','бассейн','бедный','бежать','без','бейсбол','белый','берег','бесплатный','библиотека','бизнес','бизнесмен','билет','биография','биолог','биология','бить','благодарить','близко','бог','богатый','болен','больна','больны','больше','большой','брат','брать','будущий','буква','булочная','бумага','бутерброд','бутылка','бывать','быстро','быстрый','быть','в','во','вагон','важно','важный','варить','ваш','вверх','вдруг','верх','везде','везти','век','великий','верить','вернуться','весело','возвращаться','весенний','веселый','весна','весной','весь','вся','все','ветер','вечер','вечером','вещь','взять','видео','видеть','виза','вилка','вино','висеть','включать','вкусно','вкусный','включить','вместе','вниз','внимание','внимательно','внимательный','внук','вкучка','время','вовремя','вода','водить','водка','возвращаться', 'воздух','возить','возможно','войти','входить','вокзал','волейбол','волосы','вопрос','восемнадцать','восемь','восемьдесят','восемьсот','воскресенье','восток','восточный','восьмой','вот','вперед','враг','врач','время','всегда','всего','вспоминать','вспомнить','вставать','встать','встретить','встречать','встретиться','встречаться','встреча','встречать','встретить','вторник','второй','вход','входить','войти','вчера','вчерашний','вы','выбирать','выбрать','выйти','выходить','выключать','выключить','вымыть','вырасти','высокий','высоко','выставка','выступать','выступить','выучить','выход','выходить','выйти','газета','галерея','где','географ','геограический','география','герой','гитара','главный','глаз','глубокий','говорить','сказать','год','голова','голос','голубой','гора','город','городской','горький','горячий','господин','госпожа','господа','гостиница','гость','государственный','государство','готов','готовить','приготовить','градус','граница','грамм','грипп','громко','группа','грустно','грустный','грязный','гулять','да','давай','давайте','дать','давать','давно','даже','далеко','далекий','дарить','подарить','дата','два','две','двадцать','двенадцать','дверь','двести','двое','дворец','девочка','девушка','девяносто','девятнадцать','девятый','девять','девятьсот','дедушка','декабрь','делать','сделать','дело','день','деньги','депутат','деревня','дерево','держать','десятый','десять','дети','детский','детство','дешевый','дешево','диалог','диван','директор','длинный','днем','до','добрый','доволен','доехать','дождь','доказать','доказывать','документ','долго','должен','дом','дома','домашний','домой','домохозяйка','дорога','дорого','дорогой','свидание','дочь','друг','другой','дружба','дружный','думать','подумать','душ','дядя','европейский','его','ее','еда','ездить','если','есть','ехать','еще','елка','жалко','жаль','жарко','ждать','подождать','желать','пожелать','жена','женат','жениться','женский','женщина','желтый','жив','живой','живопись','животное','жизнь','житель','жить','прожить','журнал','журналист','за','забывать','забыть','завтра','завтрак','завтракать','позавтракать','завод','задавать','задать','задание','задача','заказать','заказывать','заканчивать','закончить','закон','закрывать','закрыть','закрыт','зал','замечательный','замечать','заметить','замуж','замужем','заниматься','заняться','занят','занятие','запад','западный','заплатить','платить','запоминать','запомнить','зачем','звать','звонить','позвонить','звонок','звук','здание','здесь','здоров','здоровый','здравствуйте','здравствуй','зеленый','земля','зеркало','зима','зимний','зимой','злой','знакомиться','знакомить','познакомить','познакомиться','знаком','знакомый','знать','узнавать','значение','значить','золото','золотой','зонт','зонтик','зоопарк','зуб','и','игра','играть','сыграть','выиграть','переиграть','игрушка','идти','из','известный','извините','извини','изменить','изменять','изучать','изучить','или','имя','инженер','иногда','иностранец','иностранка','иностранный','институт','интересно','интересный','интересоваться','интересовать','интернет','искать','искусство','испанец','испанцы','испанка','испанский','историк','исторический','история','их','июль','июнь','к','ко','кабинет','каждый','казаться','как','какой','каникулы','карандаш','карта','картина','картофель','касса','кафе','каша','квартира','килограмм','километр','кино','киоск','китаец','китайцы','китайский','китаянка','класс','класть','положить','клуб','ключ','книга','книжный','когда','колбаса','команда','комедия','комната','композитор','компьютер','конверт','конец','конечно','конфета','концерт','кончать','кончить','кончаться','кончиться','копейка','корабль','коридор','коричневый','короткий','космический','космонавт','космос','костюм','который','кофе','кошка','красивый','красный','кресло','кровать','круглый','ксерокс','кто','кто-то','куда','культура','купить','покупать','курить','курица','куры','курс','куртка','кухня','лампа','левый','легко','лежать','лекарство','лекция','лес','лестница','летать','лететь','летний','лето','летом','легкий','лимон','литература','лифт','лицо','лоб','ложка','луна','лучше','хорошо','хороший','лыжи','лыжа','любимый','любить','любовь','люди','магазин','магнитофон','май','маленький','мало','мальчик','мама','марка','март','масло','математик','математика','мать','машина','медицина','медленно','медленный','медсестра','международный','менеджер','меньше','менять','поменять','место','месяц','метр','метро','мечта','мешать','мечтать','помешать','милиционер','милиция','миллион','минус','минутка','минута','минуточка','мир','мирный','младший','многие','много','больше','можный','может',\n",
    "'можно','мой','моя','мои','молодежный','молодежь','молодец','молодцы','молодой','молодость','молоко','молчать','момент','море','мороженое','москвич','москвичка','московский','москва','мочь','смочь','муж','мужской','мужчина','музей','музыка','музыкальный','музыкант','мультфильм','мы','мыло','мыть','вымыть','мягкий','мясо','мяч','на','наверное','надеяться','надо','назад','называться','найти','находить','наконец','налево','написать','писать','направо','напротив','нарисовать','рисовать','народ','народный','наука','научиться','учиться','научный','находить','найти','находиться','национальный','начало','начать','начинать','начинаться','начаться','наш','не','небо','невозможно','недавно','недалеко','неделя','нельзя','немец','немцы','немецкий','немка','несколько','несчастный','несчастье','нет','только','нигде','никогда','никто','никуда','ничего','ничто','но','новость','новый','нога','нож','ноль','номер','нулевой','нормально','нос','носок','носки','ночь','ночью','ноябрь','нравиться','понравиться','нужен','нужны','нужный','о','об','обед','обедать','пообедать','обещать','пообещать','образование','обувь','общежитие','общество','общий','объявление','объяснять','объяснить','обыкновенный','обычно','обычный','обязательство','овощ','овощи','овощной','огромный','одеваться','одеться','надеть','одежда','один','одна','одно','одинаковый','одиннадцать','однажды','озеро','оканчивать','окончить','окно','около','октябрь','он','она','оно','они','опаздывать','опоздать','опасно','опера','оптимист','опытный','опять','организовать','организовывать','осенний','осень','осенью','лсматривать','осмотреть','особенно','остановка','осторожно','остров','ответ','ответить','отвечать','отдохнуть','отдыхать','отдых','отец','открывать','открыть','открываться','открыться','открыт','открытка','откуда','отлично','отсюда','оттуда','отчество','очень','очки','ошибка','палец','пальто','памятник','папа','парк','паспорт','певец','певица','пенсионер','пенсионерка','пенсия','первый','перевести','переводить','перевод','переводчик','передавать','передать','передача','радиопередача','телепередача','перейти','переходить','перерыв','переход','песня','петь','печенье','пешком','пианино','пиво','писатель','писать','написать','письмо','пить','выпить','плавать','план','платить','заплатить','платье','плащ','плеер','плохо','хуже','плохой','площадь','плыть','плюс','по','по-английски','победа','победить','поблагодарить','благодарить','побывать','бывать','поверить','верить','повторить','повторять','погода','подарить','дарить','подарок','подождать','подруга','подумать','поезд','поездка','поехать','пожалуйста','позвать','позвонить','звонить','поздно','поздравить','поздравлять','познакомиться','по-испански','пойти','пока','показать','показывать','по-китайски','покупать','купить','пол','поле','полезный','поликлиника','политика','политический','полка','половина','положить','класть','полтора','получать','получить','полюбить','помнить','помогать','помочь','по-моему','понедельник','по-немецки','понимать','понять','понравиться','нравиться','понятно','пообедать','попросить','популярный','по-русски','послать','посылать','после','последний','послушать','слушать','посмотреть','смотреть','посоветовать','советовать','посольство','поставить','ставить','построить','строить','поступать','поступить','посылать','послать','потерять','терять','потом','потому','поужинать','ужинать','по-французски','почему','почта','почти','поэзия','поэт','поэтому','появиться','появляться','прав','права','правы','правда','правильно','правительство','правый','праздник','предмет','президент','прекрасно','прекрасный','преподаватель','преподавательница','преподавать','привет','пригласить','приглашать','приезд','приезжать','приехать','прийти','приходить','пример','природа','причина','приятно','проблема','программа','продавать','продать','продавец','продавщица','продолжать','продолжить','продолжаться','продукты','пройти','просить','попросить','проспект','простой','профессия','профессор','процент','прочитать','читать','прошлый','прямо','психолог','психология','птица','путешествовать','пятнадцать','пятница','пятый','пять','пятьдесят','пятьсот','работа','работать','рабочий','рад','рады','рада','радио','радость','раз','разговаривать','размер','разный','район','рано','раньше','рассказ','рассказать','рассказывать','расти','вырасти','ребенок','дети','редко','режиссер','результат','река','религия','ресторан','решать','решить','рис','рисовать','нарисовать','родина','родители','родиться','родной','рождение','роль','роман','российский','рот','рубашка','рубль','рука','русский','русская','ручка','рыба','рынок','рядом','с','со','сад','садиться','сесть','сажать','салат','сам','самолет','самостоятельно','самый','сантиметр','сапоги','сахар','цвет','свет','светлый','свободный','свой','своя','свое','сдавать','сдать','сделать','себя','север','северный','сегодня','седьмой','сейчас','секретарь','секунда','семнадцать','семь','семьдесят','семьсот','семья','сентябрь','сердце','серый','серьезно','серьезный','сестра','сигарета','сидеть','сильный','симпатичный','синий','система','сказать','говорить','сказка','сколько','скоро','скрипка','скучно','сладкий','слева','следующий','словарь','слово','случай','случаться','случиться','слушать','слышать','смелый','смерть','смешной','смеяться','смотреть','посмотреть','смочь','мочь','сначала','снег','снова','собака','собирать','собрать','собор','собрание','совет','советовать','посоветовать','современный','согласен','согласный','сок','солнце','соль','сообщать','сообщить','сообщение','сорок','сосед','соседка','соседний','спасибо','спать','спеть','петь','специалист','специальность','спокойно','спокойный','спорт','спортивный','спортсмен','справа','спрашивать','спросить','сразу','среда','средний','стадион','стакан','станция','старость','старший','старый','стать','статья','стена','стихи','сто','стоить','стол','столица','столовая','стоять','страна','страница','строитель','строительный','строить','построить','студент','студентка','студенческий','стул','суббота','сувенир','сумка','суп','сутки','счастливый','счастье','съесть','есть','сыграть','сын','сыр','сюда','так','также','такой','такая','такси','талант','талантливый','там','танец','танцевать','тарелка','твердый','твой','театр','текст','телевизор','телеграмма','телефон','температура','теннис','теперь','тепло','тетрадь','техника','технический','темный','теплый','тетя','тихо','товарищ','тогда','то','тоже','только','торт','та','те','точка','точно','трамвай','транспорт','тратить','третий','три','тридцать','тринадцать','триста','троллейбус','трудно','трудный','туда','турист','тут','туфли','ты','тысяча','тяжелый','у','убивать','убить','уважать','уважаемый','уверен','увидеть','видеть','ударение','удивительный','удобный','удовольствие','уезжать','уехать','уже','ужинать','ужин','узкий','уйти','уходить','улица','улыбаться','улыбнуться','умереть','уметь','суметь','умный','универмаг','университет','университетский','упасть','падать','упражение','урок','успех','уставать','устать','утро','ухо','утром','уходить','участвовать','учебник','учебный','ученик','ученица','учитель','учительница','учить','выучить','фабрика','факс','факультет','фамилия','февраль','фермер','физик','физика','физический','филолог','филологический','филология','философ','философия','философский','фильм','фирма','флешка','фонтан','фотоаппарат','фотографировать','фотография','фраза','француз','французский','француженка','фрукты','футбол','футболист','характер','химик','химический','химия','хлеб','хобби','ходить','хозяин','хозяйка','хоккеист','хоккей','холодно','холодный','хороший','хорошо','хотеть','художник','хуже','царь','цветной','цветы','целовать','целый','цена','центр','центральный','цирк','цифра','чай','чайник','час','часто','часть','часы','чашка','чей','чья','чье','чьи','человек','чем','чемпион','через','честный','четверг','четвертый','четыре','четыреста','четырнадцать','черный','число','чистый','читальный','читатель','читать','прочитать','чтение','что','чтобы','чувствовать','шапка','шарф','шахматист','шахматы','шестой','шестнадцать','шесть','шестьдесят','шестьсот','широкий','шкаф','школа','школьник','школьница','шоколад','шуметь','шумный','шутить','пошутить','шутка','щи','экзамен','экономика','экономист','экономический','экскурсия','экскурсовод','энергичный','энергия','этаж','этот','это','эта','эти','юбка','юг','южный','юмор','юность','юноша','юридический','юрист','я','яблоко','являться','ягода','язык','яйцо','январь','яркий')\n",
    "B1 = ('абсолютно','автобусный','автомат','анализ','азиатский','академия','альбом','американец','американка','америка','ангина','анкета','ансамбль','армия','анализировать','аналитический','атмосфера','атом','атомный','афиша','балерина','балет','балкон','банан','бандероль','батон','башня','бегать','береза','беречь','сберегать','уберегать','беседа','беседовать','беспокоиться','обеспокоенный','благодаря','бланк','бледный','ближе','вблизи','близкий','блюдо','бой','более','болезнь','болельщик','больница','больно','борода','бороться','борщ','борьба','ботинок','ботинки','бояться','опасаться','брить','бриться','бросать','бросить','брюки','будущее','буфет','бы','ваза','бывший','ванная','вверху','вдвоем','вежливый','повезти','велик','велосипед','верный','верхний','вести','вечерний','виноград','власть','внизу','внутри','вовремя','вопервых','вовторых','водить','возраст','война','сходить','воевать','военный','вокзал','вокруг','волк','','втретьих','вчетвертых','впятых','воспитание','воспитать','воспитывать','воспоминание','впервые','впереди','впечатление','вредно','вредный','вслух','выезжать','выехать','вызвать','вызывать','выздоравливать','выздороветь','выиграть','выигрывать','вылечить','лечить','выпить','пить','выполнить','выполнять','выражать','выразить','вырасти','расти','','выступление','выше','газ','галстук','гараж','гастроном','гденибудь','гдето','генерал','геолог','геология','геологический','гимназия','гимнастка','гимнаст','гимнастика','глава','глагол','глубже','глупо','глупый','говядина','голодный','голос','гордиться','гордый','горе','гореть','горло','гостеприимный','гражданин','гражданка','гражданство','грамматика','граница','громкий','громче','грубый','грудь','грязно','гуманитарный','дальше','дальний','дача','дважды','двое','двигаться','движение','двойка','двор','действие','действительно','декан','декларация','делегация','делиться','разделиться','демократический','демонстрация','деревянный','детектив','деятель','джинсы','диктант','дипломат','дирижер','диск','диссертация','длина','добавить','добавлять','добиться','добиваться','доброта','договариваться','договориться','доезжать','доехать','дойти','доходить','доклад','докктор','документальный','долгий','доска','достигать','достигнуть','достаточно','дочка','древний','дружеский','дружить','душа','дышать','единственный','единый','ежегодно','ежегодный','ежедневно','ежедневный','жареный','же','желание','железный','желудок','жених','жестокий','живот','заболеть','болеть','заботиться','зависеть','закрыться','закрываться','закурить','закусить','закуска','заменить','заменять','замолчать','молчать','менять','занять','занимать','записка','записывать','записать','заплакать','запретить','запрещать','зарплата','зарубежный','засмеяться','затем','заходить','захотеть','зачем','зачет','защитить','защищать','заявление','заяц','звать','звезда','зверь','землетрясение','знак','знаменитый','знание','зритель','зубной','идея','изза','изобразить','изображать','известно','изучение','иметь','импорт','истратить','тратить','будто','каков','календарь','каменный','камень','капуста','карточка','кассир','катастрофа','кататься','кафедра','качество','кашель','кефир','классический','климат','когданибудь','когдато','когдалибо','количество','коллега','колледж','коллекция','кольцо','команда','командировка','конкурс','консерватория','конспектировать','конспект','конституция','консультация','контрольный','конференция','коньки','конек','кормить','покормить','коробка','корова','корпус','кот','котлета','кошелек','красиво','кремль','крепкий','крепче','крестьянин','кризис','крикнуть','кричать','критиковать','кровь','кроме','кроссовки','кроссовок','крупный','крыша','ктонибудь','ктолибо','ктото','курить','куртка','кухня','лаборатория','легче','лечить','лечь','ложиться','лед','летчик','ли','лист','литературный','лишний','ловить','поймать','лодка','ложка','ломать','сломать','лошадь','лук','любой','мал','меньше','маршрут','маршрутка','мастер','матч','мебель','медведь','между','мелодия','меньшинство','мертвый','миллиард','млрд','тыс','руб','млн','милый','мимо','министр','минус','мировой','митинг','мнение','мобильный','модель','монета','мокрый','мороз','морской','моряк','мост','мужественный','мужество','мысль','мягкий','наблюдать','наверх','наверху','навещать','навестить','навсегда','навстречу','награда','над','надевать','надеть','надежда','надолго','название','наиболее','наизусть','намного','наоборот','напечатать','печатать','напомнить','напоминать','направление','население','насколько','насморк','настроение','наступать','наступить','наука','научный','научить','учить','невеста','негде','независимость','некогда','некоторый','необходимо','немедленно','необыкновенный','неожиданно','непрерывно','неприятность','нервный','несколько','несмотря','на','нести','неужели','нефть','нечего','ни','нигде','никакой','ничей','но','новогодний','носить','ночной','ну','обидеть','обижать','обидеться','обижаться','обладать','облако','область','обмен','обойти','обходить','обрадовать','радовать','образец','образование','обратить','обращать','обращаться','обратиться','обсудить','обсуждать','обувь','обучать','обучить','обучение','обходить','общежитие','общественный','общество','общий','объединять','объединить','объявить','объявлять','объявление','объяснение','объяснять','объяснить','обычай','овца','огонь','огромный','огурец','однако','оказаться','оказываться','океан','окончание','окончить','оканчивать','опасность','организация','операция','описывать','описать','оригинальный','оружие','освобождать','освободить','особенность','особый','оставаться','остаться','оставлять','оставить','останавливаться','остановить','остановка','от','отдавать','отдать','отметка','отнимать','отнять','относиться','отношение','отойти','отходить','отсталый','отпуск','отъезд','офицер','официальный','официант','оформлять','оформить','оценивать','оценить','оценка','ошибаться','ошибиться','падать','упасть','падеж','память','парламент','партия','пассажир','педагогический','перевозить','перевезти','переговоры','перед','переезжать','переехать','перерыв','пересадка','перчатки','песок','пессимист','пирог','пирожок','пирожное','пицца','плечо','побежать','бежать','побеждать','погибать','погибнуть','под','подготовиться','готовиться','подготовка','поднимать','поднять','подниматься','подписать','подписывать','подойти','подходить','поесть','пожелать','пожениться','позавчера','позвонить','звонить','позже','показывать','показать','покупатель','полезно','поликлиника','политехнический','полный','половина','полотенце','полтора','пользоваться','поменять','менять','помешать','мешать','помидор','помоему','пообещать','обещать','попрежнему','попробовать','пробовать','поражение','порт','портрет','посетить','посещать','посидеть','последний','послезавтра','пословица','посол','постараться','стараться','постоянно','потвоему','потолок','потратить','похвалить','хвалить','похожий','похож','почувствовать','чувствовать','пошутить','шутить','правило','практика','практический','предлагать','предложить','представитель','прежде','чем','премия','привезти','привозить','приводить','привести','привыкать','привыкнуть','пригласить','приглашать','приготовить','готовить','приказать','приказывать','прилетать','прилететь','принадлежность','принести','приносить','принимать','принять','прислать','присылать','пробовать','попробовать','проверить','проверять','провести','проводить','провожать','проводить','прогресс','прогулка','продавец','продавщица','провожать','проводить','продать','продавать','продолжать','продолжить','продолжается','продолжиться','проезжать','проехать','произведение','производить','произвести','производство','произносить','произнести','произношение','промышленность','промышленный','простить','прощать','просыпаться','проснуться','против','прохладно','прохладный','проходить','пройти','процесс','прощаться','попрощаться','прыгать','прыгнуть','психологический','пустой','пусть','путешественник','путь','пытаться','попытаться','пьеса','пятерка','равен','равный','радовать','обрадовать','радоваться','обрадоваться','разве','развиваться','развитие','разделить','делить','разделиться','делиться','разговор','разница','разрешать','разрешить','расписание','ребята','революция','регулярно','редкий','реже','резать','результат','ректор','республика','рецепт','решительный','рисунок','ровно','род','родственник','рождество','розовый','роза','рояль','ругать','руководитель','руководить','рыбак','ряд','салют','самовар','сберечь','беречь','сварить','варить','свежий','свидание','свинина','свитер','свобода','свободен','связь','седой','секунда','сельский','хозяйство','семейный','семестр','семинар','серебро','серебряный','середина','серый','сессия','сибирский','сила','символ','ситуация','скидка','скорость','скромный','слабый','славянский','следовательно','слишком','сложный','сломать','ломать','слон','служить','смысл','событие','совет','советский','сожаление','совсем','создавать','создать','солдат','сомневаться','сон','соревнование','состоять','соус','сохранить','сохранять','социальный','спасти','спасать','спектакль','специальный','спешить','спина','спички','спорить','способный','спутник','сравнивать','сравнить','среди','ставить','поставить','становиться','стать','стараться','постараться','старик','старость','старше','старый','стипендия','страдать','постирать','столько','сторона','странный','страшный','строго','стройка','стыдно','судьба','сухой','существовать','сфотографировать','сцена','счет','считать','посчитать','сшить','шить','съезд','таблетка','тайна','такой','образ','таможня','творчество','тело','тема','темно','темный','теоретический','теория','теплоход','территория','терять','потерять','тихий','тишина','товар','толстый','тонкий','торговля','торт','зрение','точный','трава','трагедия','традиция','истратить','потратить','требовать','потребовать','тренироваться','тренировка','трое','тройка','труд','трудолюбивый','туман','туманный','тюрьма','убегать','убежать','убедить','убеждать','убирать','убрать','уважаемый','уважать','увезти','увозить','увеличивать','увеличиваться','увлекаться','увлечься','увлечение','угол','уголь','удаваться','удасться','ударить','удобно','ужасно','ужасный','узнавать','узнать','уйти','уходить','укол','улетать','улететь','улучшать','улучшить','улучшаться','улучшиться','улыбка','уменьшать','уменьшиться','умываться','умывать','умыться','уникальный','урожай','условие','услышать','слышать','успевать','успеть','успешно','успешный','успокаиваться','успокоиться','уставать','усталый','устно','устный','усы','утренний','училище','факт','фашизм','фашист','фестиваль','фигурный','катание','флаг','фонтан','форма','фронт','футбольный','хвалить','хватать','хватить','хирург','хозяйство','домашний','дом','хор','хотеться','хотя','храм','художественный','художник','худой','царь','целоваться','поцеловаться','цель','цена','ценный','центр','центральный','церковь','чейнибудь','чейто','человечество','чемодан','чемпионат','четверо','четверка','член','чтение','чутьчуть','чтото','чтонибудь','чужой','чудо','чувство','шашлык','шестнадцать','шея','шить','сшить','шляпа','шоссе','шофер','шум','шуметь','шумный','щека','щетка','экология','экологический','экономить','экспедиция','эксперимент','экспорт','электричество','электростанция','электроника','этап','эпоха','энциклопедия','ядерный','ясно','ясный')\n",
    "VN1 = ('анализ','донос','захват','насос','отказ','подбор','приток','размен','созыв','блеск','допуск','заход','настил','отклик','подвиг','прихлоп','размер','состав','ввод','досмотр','защита','настой','откорм','поджог','приход','размыв','спад','ввоз','дрожь','звон','настрой','отлет','подкова','прицеп','разнос','сплав','взгляд','езда','извив','насыпь','отмена','подкоп','причал','разрез','спор','вздох','забег','изгиб','набор','отпуск','подкуп','прищур','разруха','спрос','взлет','забой','излом','недосмотр','отрез','подмена','приют','разрыв','сруб','взмах','забор','измена','обвал','отрыв','поднос','пробег','разъезд','срыв','взнос','забота','изморозь','обгон','отряд','подпись','провал','раскат','ссора','взор','завал','износ','обет','отсвет','подрыв','провод','раскол','ссуда','взрыв','завеса','импорт','обжиг','отсек','подступ','проводы','раскоп','стон','визг','завет','исповедь','обзор','отстой','подсчет','прогиб','раскрой','страда','вклад','зависть','испуг','обида','отступ','подход','прогноз','распад','стрекот','вкус','завод','исток','обман','отсчет','подъезд','прогон','расплав','стужа','возврат','завоз','исход','обмен','оттиск','подъем','прогул','расплата','стык','возглас','загар','итог','обмер','отход','позор','проезд','расправа','суета','возраст','загиб','клев','обмолот','отчет','поиск','происки','рассвет','сход','восторг','загон','клевета','оборона','отъезд','показ','пролет','рассказ','счет','вражда','задира','клей','обрез','охват','поклон','пролог','расспрос','съезд','вскрик','заезд','клеймо','обрыв','охота','покой','пролом','расстрел','торговля','всплеск','зажим','конспект','обряд','охрана','покос','промах','раствор','тормоз','встреча','заказ','контраст','обстрел','перебор','покров','пропись','растрата','травля','всхлип','закал','ловля','обхват','перевал','полет','пропуск','расход','трепет','всходы','закат','лом','обход','перевес','полив','прорезь','расцвет','треск','въезд','залежь','мах','объезд','перевод','помета','прорубь','расчет','убор','выбор','залив','набег','обыск','перевоз','помеха','прорыв','розыск','угар','выброс','залог','набор','ограда','перевыборы','пороша','просвет','рокот','уговор','вывих','замах','навал','ожог','перевязь','порча','просмотр','ропот','угроза','вывод','замена','навес','окись','перегрев','посол','простуда','роспись','удав','вывоз','замер','нагрев','оклик','передел','поступь','просчет','россыпь','удар','выговор','замес','надел','оковы','переезд','потеха','протест','рост','удел','выдох','замысел','надзор','окоп','перекат','поток','проток','сбор','уклад','выезд','занавес','надпись','окрик','перекись','похвала','протока','сброс','уклон','вызов','запас','надрез','опись','перелет','почет','проход','свист','укол','выкрик','запад','надрыв','опора','перелом','пощада','пряжа','сгиб','укор','выкуп','запал','нажива','оправа','перемена','преграда','разбег','сговор','укус','вылет','запас','нажим','опрос','перенос','прибой','разбор','сдвиг','улика','вымысел','запах','наказ','ориентир','перепад','привал','разброд','склад','умысел','выпас','запись','накал','осада','переплет','привет','развал','скорбь','уплата','выплата','запор','накат','оскал','переправа','привод','развод','скос','упор','выпуск','запрет','накипь','осмотр','перерасход','приговор','разворот','скрежет','упрек','вырез','запрос','наклон','отблеск','перерыв','приезд','разгар','скрип','уровень','высев','запруда','налет','отбой','пересев','прием','разговор','скука','урон','выслуга','запуск','налив','отбор','пересказ','призыв','разгон','слет','услуга','выстрел','зарок','налог','отброс','пересмотр','приказ','разгром','слом','уступ','выступ','заряд','намек','отвал','пересчет','приклад','разгул','смена','утрата','выхлоп','засада','намыв','ответ','перехват','прилет','раздел','смесь','уход','выход','засев','нанос','отвод','переход','примесь','раздор','смотр','учет','вычет','заслон','наплыв','отдел','побег','примета','разлад','смута','хвала','довод','заслуга','нарост','отдых','победа','прирост','разлив','смыв','хохот','договор','застава','нарыв','отек','повод','присмотр','разлом','смысл','хруст','доклад','засуха','наряд','отзвук','повтор','приступ','разлука','снаряд','шелест','домысел','затрата','наскок','отзыв','погоня','присяга','размах','снос','шум')\n",
    "stopwords = [\"c\",\"а\",\"алло\",\"без\",\"белый\",\"близко\",\"более\",\"больше\",\"большой\",\"будем\",\"будет\",\"будете\",\"будешь\",\"будто\",\"буду\",\"будут\",\"будь\",\"бы\",\"бывает\",\"бывь\",\"был\",\"была\",\"были\",\"было\",\"быть\",\"в\",\"важная\",\"важное\",\"важные\",\"важный\",\"вам\",\"вами\",\"вас\",\"ваш\",\"ваша\",\"ваше\",\"ваши\",\"вверх\",\"вдали\",\"вдруг\",\"ведь\",\"везде\",\"вернуться\",\"весь\",\"вечер\",\"взгляд\",\"взять\",\"вид\",\"видел\",\"видеть\",\"вместе\",\"вне\",\"вниз\",\"внизу\",\"во\",\"вода\",\"война\",\"вокруг\",\"вон\",\"вообще\",\"вопрос\",\"восемнадцатый\",\"восемнадцать\",\"восемь\",\"восьмой\",\"вот\",\"впрочем\",\"времени\",\"время\",\"все\",\"все еще\",\"всегда\",\"всего\",\"всем\",\"всеми\",\"всему\",\"всех\",\"всею\",\"всю\",\"всюду\",\"вся\",\"всё\",\"второй\",\"вы\",\"выйти\",\"г\",\"где\",\"главный\",\"глаз\",\"говорил\",\"говорит\",\"говорить\",\"год\",\"года\",\"году\",\"голова\",\"голос\",\"город\",\"да\",\"давать\",\"давно\",\"даже\",\"далекий\",\"далеко\",\"дальше\",\"даром\",\"дать\",\"два\",\"двадцатый\",\"двадцать\",\"две\",\"двенадцатый\",\"двенадцать\",\"дверь\",\"двух\",\"девятнадцатый\",\"девятнадцать\",\"девятый\",\"девять\",\"действительно\",\"дел\",\"делал\",\"делать\",\"делаю\",\"дело\",\"день\",\"деньги\",\"десятый\",\"десять\",\"для\",\"до\",\"довольно\",\"долго\",\"должен\",\"должно\",\"должный\",\"дом\",\"дорога\",\"друг\",\"другая\",\"другие\",\"других\",\"друго\",\"другое\",\"другой\",\"думать\",\"душа\",\"е\",\"его\",\"ее\",\"ей\",\"ему\",\"если\",\"есть\",\"еще\",\"ещё\",\"ею\",\"её\",\"ж\",\"ждать\",\"же\",\"жена\",\"женщина\",\"жизнь\",\"жить\",\"за\",\"занят\",\"занята\",\"занято\",\"заняты\",\"затем\",\"зато\",\"зачем\",\"здесь\",\"земля\",\"знать\",\"значит\",\"значить\",\"и\",\"иди\",\"идти\",\"из\",\"или\",\"им\",\"имеет\",\"имел\",\"именно\",\"иметь\",\"ими\",\"имя\",\"иногда\",\"их\",\"к\",\"каждая\",\"каждое\",\"каждые\",\"каждый\",\"кажется\",\"казаться\",\"как\",\"какая\",\"какой\",\"кем\",\"книга\",\"когда\",\"кого\",\"ком\",\"комната\",\"кому\",\"конец\",\"конечно\",\"которая\",\"которого\",\"которой\",\"которые\",\"который\",\"которых\",\"кроме\",\"кругом\",\"кто\",\"куда\",\"лежать\",\"лет\",\"ли\",\"лицо\",\"лишь\",\"лучше\",\"любить\",\"люди\",\"м\",\"маленький\",\"мало\",\"мать\",\"машина\",\"между\",\"меля\",\"менее\",\"меньше\",\"меня\",\"место\",\"миллионов\",\"мимо\",\"минута\",\"мир\",\"мира\",\"мне\",\"много\",\"многочисленная\",\"многочисленное\",\"многочисленные\",\"многочисленный\",\"мной\",\"мною\",\"мог\",\"могу\",\"могут\",\"мож\",\"может\",\"может быть\",\"можно\",\"можхо\",\"мои\",\"мой\",\"мор\",\"москва\",\"мочь\",\"моя\",\"моё\",\"мы\",\"на\",\"наверху\",\"над\",\"надо\",\"назад\",\"наиболее\",\"найти\",\"наконец\",\"нам\",\"нами\",\"народ\",\"нас\",\"начала\",\"начать\",\"наш\",\"наша\",\"наше\",\"наши\",\"не\",\"него\",\"недавно\",\"недалеко\",\"нее\",\"ней\",\"некоторый\",\"нельзя\",\"нем\",\"немного\",\"нему\",\"непрерывно\",\"нередко\",\"несколько\",\"нет\",\"нею\",\"неё\",\"ни\",\"нибудь\",\"ниже\",\"низко\",\"никакой\",\"никогда\",\"никто\",\"никуда\",\"ним\",\"ними\",\"них\",\"ничего\",\"ничто\",\"но\",\"новый\",\"нога\",\"ночь\",\"ну\",\"нужно\",\"нужный\",\"нх\",\"о\",\"об\",\"оба\",\"обычно\",\"один\",\"одиннадцатый\",\"одиннадцать\",\"однажды\",\"однако\",\"одного\",\"одной\",\"оказаться\",\"окно\",\"около\",\"он\",\"она\",\"они\",\"оно\",\"опять\",\"особенно\",\"остаться\",\"от\",\"ответить\",\"отец\",\"откуда\",\"отовсюду\",\"отсюда\",\"очень\",\"первый\",\"перед\",\"писать\",\"плечо\",\"по\",\"под\",\"подойди\",\"подумать\",\"пожалуйста\",\"позже\",\"пойти\",\"пока\",\"пол\",\"получить\",\"помнить\",\"понимать\",\"понять\",\"пор\",\"пора\",\"после\",\"последний\",\"посмотреть\",\"посреди\",\"потом\",\"потому\",\"почему\",\"почти\",\"правда\",\"прекрасно\",\"при\",\"про\",\"просто\",\"против\",\"процентов\",\"путь\",\"пятнадцатый\",\"пятнадцать\",\"пятый\",\"пять\",\"работа\",\"работать\",\"раз\",\"разве\",\"рано\",\"раньше\",\"ребенок\",\"решить\",\"россия\",\"рука\",\"русский\",\"ряд\",\"рядом\",\"с\",\"с кем\",\"сам\",\"сама\",\"сами\",\"самим\",\"самими\",\"самих\",\"само\",\"самого\",\"самой\",\"самом\",\"самому\",\"саму\",\"самый\",\"свет\",\"свое\",\"своего\",\"своей\",\"свои\",\"своих\",\"свой\",\"свою\",\"сделать\",\"сеаой\",\"себе\",\"себя\",\"сегодня\",\"седьмой\",\"сейчас\",\"семнадцатый\",\"семнадцать\",\"семь\",\"сидеть\",\"сила\",\"сих\",\"сказал\",\"сказала\",\"сказать\",\"сколько\",\"слишком\",\"слово\",\"случай\",\"смотреть\",\"сначала\",\"снова\",\"со\",\"собой\",\"собою\",\"советский\",\"совсем\",\"спасибо\",\"спросить\",\"сразу\",\"стал\",\"старый\",\"стать\",\"стол\",\"сторона\",\"стоять\",\"страна\",\"суть\",\"считать\",\"т\",\"та\",\"так\",\"такая\",\"также\",\"таки\",\"такие\",\"такое\",\"такой\",\"там\",\"твои\",\"твой\",\"твоя\",\"твоё\",\"те\",\"тебе\",\"тебя\",\"тем\",\"теми\",\"теперь\",\"тех\",\"то\",\"тобой\",\"тобою\",\"товарищ\",\"тогда\",\"того\",\"тоже\",\"только\",\"том\",\"тому\",\"тот\",\"тою\",\"третий\",\"три\",\"тринадцатый\",\"тринадцать\",\"ту\",\"туда\",\"тут\",\"ты\",\"тысяч\",\"у\",\"увидеть\",\"уж\",\"уже\",\"улица\",\"уметь\",\"утро\",\"хороший\",\"хорошо\",\"хотел бы\",\"хотеть\",\"хоть\",\"хотя\",\"хочешь\",\"час\",\"часто\",\"часть\",\"чаще\",\"чего\",\"человек\",\"чем\",\"чему\",\"через\",\"четвертый\",\"четыре\",\"четырнадцатый\",\"четырнадцать\",\"что\",\"чтоб\",\"чтобы\",\"чуть\",\"шестнадцатый\",\"шестнадцать\",\"шестой\",\"шесть\",\"эта\",\"эти\",\"этим\",\"этими\",\"этих\",\"это\",\"этого\",\"этой\",\"этом\",\"этому\",\"этот\",\"эту\",\"я\",\"являюсь\"]\n",
    "\n",
    "Tikhonov = pd.read_csv(\"D:\\\\Program files\\\\R\\\\Temp\\\\CB\\\\DICT\\\\Tikhonov.csv\", encoding = 'cp1251', header = 0, sep = '|', engine= 'python')\n",
    "Tikhonov.columns = ['word','morph','num']\n",
    "Tikhonov_morph = Tikhonov['morph']\n",
    "Tikhonov_morph = Tikhonov_morph.tolist()\n",
    "Tikhonov_morph = map(str, Tikhonov_morph)\n",
    "S = []\n",
    "for item in Tikhonov_morph:\n",
    "    S.append(item.count('!'))\n",
    "Tikhonov['numbers'] = S\n",
    "Tikhonov = Tikhonov.drop('num', 1)\n",
    "Tikhonov = Tikhonov.replace(r'\\s+','',regex=True)\n",
    "Tikh_dict = dict(zip(Tikhonov['word'] ,Tikhonov['numbers']))\n",
    "\n",
    "#print(Tikh_dict['ящур'])\n",
    "\n",
    "#загружаем словарь частотности и запоминаем 30% наименее частотных слов\n",
    "\n",
    "dictionary = pd.read_csv(\"D:\\\\Program files\\\\R\\\\Temp\\\\CB\\\\DICT\\\\freqrnc2011.csv\", encoding = 'utf-8', header = 0, sep='\\\\t', engine='python')\n",
    "\n",
    "dictionary1 = dictionary.drop('PoS', 1)\n",
    "dictionary1 = dictionary1.drop('R', 1)\n",
    "dictionary1 = dictionary1.drop('D', 1)\n",
    "dictionary1 = dictionary1.drop('Doc', 1)\n",
    "dictionary1 = dictionary1.sort_values(by=['Freq(ipm)'])\n",
    "dictionary2 = dictionary1[:15641] #здесь выбрано 30% наименее частотных слов\n",
    "dictionary3 = dictionary2['Lemma']\n",
    "\n",
    "full_dict = dictionary1['Lemma']\n",
    "full_dict = full_dict .tolist()\n",
    "\n",
    "\n",
    "dictionary_freq = dictionary3.tolist()\n",
    "\n",
    "#Словари для эвфонического индекса \n",
    "neblag_v_slove_sogl = (\"бв\",\"бг\",\"бд\",\"бж\",\"бз\",\"бк\",\"бл\",\"бм\",\"бн\",\"бп\",\"бр\",\"бс\",\"бт\",\"бф\",\"бх\",\"бц\",\"бч\",\"бш\",\"бщ\",\"вб\",\"вг\",\"вд\",\"вж\",\"вз\",\"вк\",\"вл\",\"вм\",\"вн\",\"вп\",\"вр\",\"вс\",\"вт\",\"вф\",\"вх\",\"вц\",\"вч\",\"вш\",\"вщ\",\"гб\",\"гв\",\"гд\",\"гж\",\"гз\",\"гк\",\"гл\",\"гм\",\"гн\",\"гп\",\"гр\",\"гс\",\"гт\",\"гф\",\"гх\",\"гц\",\"гч\",\"гш\",\"гщ\",\"дб\",\"дв\",\"дг\",\"дж\",\"дз\",\"дк\",\"дл\",\"дм\",\"дн\",\"дп\",\"др\",\"дс\",\"дт\",\"дф\",\"дх\",\"дц\",\"дч\",\"дш\",\"дщ\",\"жб\",\"жв\",\"жг\",\"жд\",\"жз\",\"жк\",\"жл\",\"жм\",\"жн\",\"жп\",\"жр\",\"жс\",\"жт\",\"жф\",\"жх\",\"жц\",\"жч\",\"жш\",\"жщ\",\"зб\",\"зв\",\"зг\",\"зд\",\"зж\",\"зк\",\"зл\",\"зм\",\"зн\",\"зп\",\"зр\",\"зс\",\"зт\",\"зф\",\"зх\",\"зц\",\"зч\",\"зш\",\"зщ\",\"кб\",\"кв\",\"кг\",\"кд\",\"кж\",\"кз\",\"кл\",\"км\",\"кн\",\"кп\",\"кр\",\"кс\",\"кт\",\"кф\",\"кх\",\"кц\",\"кч\",\"кш\",\"кщ\",\"лб\",\"лв\",\"лг\",\"лд\",\"лж\",\"лз\",\"лк\",\"лм\",\"лн\",\"лп\",\"лр\",\"лс\",\"лт\",\"лф\",\"лх\",\"лц\",\"лч\",\"лш\",\"лщ\",\"мб\",\"мв\",\"мг\",\"мд\",\"мж\",\"мз\",\"мк\",\"мл\",\"мн\",\"мп\",\"мр\",\"мс\",\"мт\",\"мф\",\"мх\",\"мц\",\"мч\",\"мш\",\"мщ\",\"нб\",\"нв\",\"нг\",\"нд\",\"нж\",\"нз\",\"нк\",\"нл\",\"нм\",\"нп\",\"нр\",\"нс\",\"нт\",\"нф\",\"нх\",\"нц\",\"нч\",\"нш\",\"нщ\",\"пб\",\"пв\",\"пг\",\"пд\",\"пж\",\"пз\",\"пк\",\"пл\",\"пм\",\"пн\",\"пр\",\"пс\",\"пт\",\"пф\",\"пх\",\"пц\",\"пч\",\"пш\",\"пщ\",\"рб\",\"рв\",\"рг\",\"рд\",\"рж\",\"рз\",\"рк\",\"рл\",\"рм\",\"рн\",\"рп\",\"рс\",\"рт\",\"рф\",\"рх\",\"рц\",\"рч\",\"рш\",\"рщ\",\"сб\",\"св\",\"сг\",\"сд\",\"сж\",\"сз\",\"ск\",\"сл\",\"см\",\"сн\",\"сп\",\"ср\",\"ст\",\"сф\",\"сх\",\"сц\",\"сч\",\"сш\",\"сщ\",\"тб\",\"тв\",\"тг\",\"тд\",\"тж\",\"тз\",\"тк\",\"тл\",\"тм\",\"тн\",\"тп\",\"тр\",\"тс\",\"тф\",\"тх\",\"тц\",\"тч\",\"тш\",\"тщ\",\"фб\",\"фв\",\"фг\",\"фд\",\"фж\",\"фз\",\"фк\",\"фл\",\"фм\",\"фн\",\"фп\",\"фр\",\"фс\",\"фт\",\"фх\",\"фц\",\"фч\",\"фш\",\"фщ\",\"хб\",\"хв\",\"хг\",\"хд\",\"хж\",\"хз\",\"хк\",\"хл\",\"хм\",\"хн\",\"хп\",\"хр\",\"хс\",\"хт\",\"хф\",\"хц\",\"хч\",\"хш\",\"хщ\",\"цб\",\"цв\",\"цг\",\"цд\",\"цж\",\"цз\",\"цк\",\"цл\",\"цм\",\"цн\",\"цп\",\"цр\",\"цс\",\"цт\",\"цф\",\"цх\",\"цч\",\"цш\",\"цщ\",\"чб\",\"чв\",\"чг\",\"чд\",\"чж\",\"чз\",\"чк\",\"чл\",\"чм\",\"чн\",\"чп\",\"чр\",\"чс\",\"чт\",\"чф\",\"чх\",\"чц\",\"чш\",\"чщ\",\"шб\",\"шв\",\"шг\",\"шд\",\"шж\",\"шз\",\"шк\",\"шл\",\"шм\",\"шн\",\"шп\",\"шр\",\"шс\",\"шт\",\"шф\",\"шх\",\"шц\",\"шч\",\"шщ\",\"щб\",\"щв\",\"щг\",\"щд\",\"щж\",\"щз\",\"щк\",\"щл\",\"щм\",\"щн\",\"щп\",\"щр\",\"щс\",\"щт\",\"щф\",\"щх\",\"щц\",\"щч\",\"щш\")\n",
    "neblag_v_slove_glasn = (\"аа\",\"ае\",\"аё\",\"аи\",\"ао\",\"ау\",\"аэ\",\"аю\",\"ая\",\"аы\",\"еа\",\"ее\",\"её\",\"еи\",\"ео\",\"еу\",\"еэ\",\"ею\",\"ея\",\"еы\",\"ёа\",\"ёе\",\"ёё\",\"ёи\",\"ёо\",\"ёу\",\"ёэ\",\"ёю\",\"ёя\",\"ёы\",\"иа\",\"ие\",\"иё\",\"ии\",\"ио\",\"иу\",\"иэ\",\"ию\",\"ия\",\"иы\",\"оа\",\"ое\",\"оё\",\"ои\",\"оо\",\"оу\",\"оэ\",\"ою\",\"оя\",\"оы\",\"уа\",\"уе\",\"уё\",\"уи\",\"уо\",\"уу\",\"уэ\",\"ую\",\"уя\",\"уы\",\"эа\",\"эе\",\"эё\",\"эи\",\"эо\",\"эу\",\"ээ\",\"эю\",\"эя\",\"эы\",\"юа\",\"юе\",\"юё\",\"юи\",\"юо\",\"юу\",\"юэ\",\"юю\",\"юя\",\"юы\",\"яа\",\"яе\",\"яё\",\"яи\",\"яо\",\"яу\",\"яэ\",\"яю\",\"яя\",\"яы\",\"ыа\",\"ые\",\"ыё\",\"ыи\",\"ыо\",\"ыу\",\"ыэ\",\"ыю\",\"ыя\",\"ыы\")\n",
    "schip = ('ж','ш','ч','щ')\n",
    "NDU_dict = neblag_v_slove_sogl + neblag_v_slove_glasn + schip\n",
    "new_list_b1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'б ' + item\n",
    "    new_list_b1.append(new)\n",
    "new_list_b2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' б'\n",
    "    new_list_b2.append(new)\n",
    "new_list_v1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'в ' + item\n",
    "    new_list_v1.append(new)\n",
    "new_list_v2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' в'\n",
    "    new_list_v2.append(new)\n",
    "new_list_g1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'г ' + item\n",
    "    new_list_g1.append(new)\n",
    "new_list_g2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' г'\n",
    "    new_list_g2.append(new)\n",
    "new_list_d1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'д ' + item\n",
    "    new_list_d1.append(new)\n",
    "new_list_d2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' д'\n",
    "    new_list_d2.append(new)\n",
    "new_list_zh1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'ж ' + item\n",
    "    new_list_zh1.append(new)\n",
    "new_list_zh2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' ж'\n",
    "    new_list_zh2.append(new)\n",
    "new_list_z1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'з ' + item\n",
    "    new_list_z1.append(new)\n",
    "new_list_z2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' з'\n",
    "    new_list_z2.append(new)\n",
    "new_list_k1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'к ' + item\n",
    "    new_list_k1.append(new)\n",
    "new_list_k2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' к'\n",
    "    new_list_k2.append(new)\n",
    "new_list_l1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'л ' + item\n",
    "    new_list_l1.append(new)\n",
    "new_list_l2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' л'\n",
    "    new_list_l2.append(new)\n",
    "new_list_m1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'м ' + item\n",
    "    new_list_m1.append(new)\n",
    "new_list_m2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' м'\n",
    "    new_list_m2.append(new)\n",
    "new_list_n1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'н ' + item\n",
    "    new_list_n1.append(new)\n",
    "new_list_n2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' н'\n",
    "    new_list_n2.append(new)\n",
    "new_list_p1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'п ' + item\n",
    "    new_list_p1.append(new)\n",
    "new_list_p2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' п'\n",
    "    new_list_p2.append(new)\n",
    "new_list_r1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'р ' + item\n",
    "    new_list_r1.append(new)\n",
    "new_list_r2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' р'\n",
    "    new_list_r2.append(new)\n",
    "new_list_s1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'с ' + item\n",
    "    new_list_s1.append(new)\n",
    "new_list_s2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' с'\n",
    "    new_list_s2.append(new)\n",
    "new_list_t1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'т ' + item\n",
    "    new_list_t1.append(new)\n",
    "new_list_t2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' т'\n",
    "    new_list_t2.append(new)\n",
    "new_list_f1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'ф ' + item\n",
    "    new_list_f1.append(new)\n",
    "new_list_f2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' ф'\n",
    "    new_list_f2.append(new)\n",
    "new_list_h1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'х ' + item\n",
    "    new_list_h1.append(new)\n",
    "new_list_h2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' х'\n",
    "    new_list_h2.append(new)\n",
    "new_list_c1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'ц ' + item\n",
    "    new_list_c1.append(new)\n",
    "new_list_c2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' ц'\n",
    "    new_list_c2.append(new)\n",
    "new_list_ch1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'ч ' + item\n",
    "    new_list_ch1.append(new)\n",
    "new_list_ch2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' ч'\n",
    "    new_list_ch2.append(new)\n",
    "new_list_sh1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'ш ' + item\n",
    "    new_list_sh1.append(new)\n",
    "new_list_sh2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' ш'\n",
    "    new_list_sh2.append(new)\n",
    "new_list_sch1 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new = 'щ ' + item\n",
    "    new_list_sch1.append(new)\n",
    "new_list_sch2 = []\n",
    "for item in neblag_v_slove_sogl:\n",
    "    new =  item + ' щ'\n",
    "    new_list_sch2.append(new)\n",
    "NDT1 = new_list_b1 + new_list_b2 + new_list_v1 + new_list_v2 + new_list_g1 + new_list_g2 + new_list_d1 + new_list_d2 + new_list_zh1 + new_list_zh2 + new_list_z1 + new_list_z2 + new_list_k1 + new_list_k2 + new_list_l1 + new_list_l2 + new_list_m1 + new_list_m2 + new_list_n1 + new_list_n2 + new_list_p1 + new_list_p2 + new_list_r1 + new_list_r2 + new_list_s1 + new_list_s2 + new_list_t1 + new_list_t2 + new_list_f1 + new_list_f2 + new_list_h1 + new_list_h2 + new_list_c1 + new_list_c2 + new_list_ch1 + new_list_ch2 + new_list_sh1 + new_list_sh2 + new_list_sch1 + new_list_sch2 \n",
    "NDT2 = [\"а а\",\"а е\",\"а ё\",\"а и\",\"а о\",\"а у\",\"а э\",\"а ю\",\"а я\",\"а ы\",\"е а\",\"е е\",\"е ё\",\"е и\",\"е о\",\"е у\",\"е э\",\"е ю\",\"е я\",\"е ы\",\"ё а\",\"ё е\",\"ё ё\",\"ё и\",\"ё о\",\"ё у\",\"ё э\",\"ё ю\",\"ё я\",\"ё ы\",\"и а\",\"и е\",\"и ё\",\"и и\",\"и о\",\"и у\",\"и э\",\"и ю\",\"и я\",\"и ы\",\"о а\",\"о е\",\"о ё\",\"о и\",\"о о\",\"о у\",\"о э\",\"о ю\",\"о я\",\"о ы\",\"у а\",\"у е\",\"у ё\",\"у и\",\"у о\",\"у у\",\"у э\",\"у ю\",\"у я\",\"у ы\",\"э а\",\"э е\",\"э ё\",\"э и\",\"э о\",\"э у\",\"э э\",\"э ю\",\"э я\",\"э ы\",\"ю а\",\"ю е\",\"ю ё\",\"ю и\",\"ю о\",\"ю у\",\"ю э\",\"ю ю\",\"ю я\",\"ю ы\",\"я а\",\"я е\",\"я ё\",\"я и\",\"я о\",\"я у\",\"я э\",\"я ю\",\"я я\",\"я ы\",\"ы а\",\"ы е\",\"ы ё\",\"ы и\",\"ы о\",\"ы у\",\"ы э\",\"ы ю\",\"ы я\",\"ы ы\"]\n",
    "NDT_dict = NDT1 + NDT2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функции для извлечения лингвистических характеристик\n",
    "\n",
    "#1 Средняя длина предложения в словах\n",
    "def SenLen(text):\n",
    "    words = textstat.lexicon_count(text, removepunct=True)\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    sentences = len(number_of_sentences)\n",
    "    return float(words / sentences)\n",
    "\n",
    "#2 Средняя длина дерева  синтаксического разбора на предложение\n",
    "def tree_height(root):\n",
    "    if not list(root.children):\n",
    "        return 1\n",
    "    else:\n",
    "        return 1 + max(tree_height(x) for x in root.children)\n",
    "def PTH(text):\n",
    "    if type(text) == str:\n",
    "        doc = nlp(text)\n",
    "    else:\n",
    "        doc = text\n",
    "    roots = [sent.root for sent in doc.sents]\n",
    "    return np.mean([tree_height(root) for root in roots])\n",
    "\n",
    "#3 Среднее число подчинительных союзов на предложение\n",
    "def SubCon(text):\n",
    "   patternSC = r'\\b(,\\sчто\\s|\\sкак\\s|чтобы\\s|когда\\s|\\sпока\\s|едва\\s|с\\sтех\\sпор\\sкак\\s|лишь|\\sпотому\\sчто\\s|потому,\\sчто|\\sтак\\sкак\\s|ибо\\s|ввиду\\s|\\sесли\\s|\\sколи\\s|\\sкабы\\s|\\sхотя\\s|\\sнесмотря\\sна\\s|\\sвопреки\\s|\\sпоэтому\\s|\\sчем\\s|словно\\s|подобно\\s)\\b'\n",
    "   text_string = text.lower()\n",
    "   number_of_sentences = sent_tokenize(text)\n",
    "   match_pattern = re.findall(patternSC, text_string)\n",
    "   return float (len(match_pattern) / len(number_of_sentences))\n",
    "\n",
    "#4 Среднее число сочинительных союзов на предложение\n",
    "def CoordC(text):\n",
    "   patternCC = r'\\b(,\\sи\\s|,\\sа\\s|,\\sно\\s|не\\sтолько|так\\sи|зато\\s|тоже|также|однако|или)\\b'\n",
    "   text_string = text.lower()\n",
    "   number_of_sentences = sent_tokenize(text)\n",
    "   match_pattern = re.findall(patternCC, text_string)\n",
    "   return float (len(match_pattern) / len(number_of_sentences))\n",
    "\n",
    "#5 Доля именных деревьев в среднем на предложение\n",
    "def NP(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    text = nlp(text)\n",
    "    S = []\n",
    "    for sent in text.sents:\n",
    "        if sent.root.pos_ == 'NOUN':\n",
    "            S.append(sent.root)\n",
    "    return float (len(S) / len(number_of_sentences))\n",
    "\n",
    "#6 Доля глагольных деревьев в среднем на предложение\n",
    "def VP(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    text = nlp(text)\n",
    "    S = []\n",
    "    for sent in text.sents:\n",
    "        if sent.root.pos_ == 'VERB':\n",
    "            S.append(sent.root)\n",
    "    return float (len(S) / len(number_of_sentences))\n",
    "\n",
    "\n",
    "#7 Среднее число цифр на предложение\n",
    "def NUM(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    text = nlp(text)\n",
    "    S = []\n",
    "    for token in text:\n",
    "        if token.pos_ == 'NUM':\n",
    "            S.append(token)\n",
    "    return float (len(S) / len(number_of_sentences))\n",
    "\n",
    "#8 Среднее число предложений, отягощенных причастиями и деепричастиями\n",
    "def DiffSynt(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    words = text.split()\n",
    "    res = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.tag.POS)\n",
    "    S = []\n",
    "    for i in res:\n",
    "        if i == 'PRTF' or i == 'PRTS' or i == 'GRND':\n",
    "            S.append(i)\n",
    "    return float(len(S) / len(number_of_sentences))\n",
    "\n",
    "#9 Доля предложений, длина которых превышает 25 слов\n",
    "def LSDaoust(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    test = sent_tokenize(text)\n",
    "    S = []\n",
    "    for sent in test:\n",
    "        words = textstat.lexicon_count(sent)\n",
    "        S.append(words)\n",
    "    A = []\n",
    "    for number in S:\n",
    "        if int(number) > 25:\n",
    "            A.append(number)\n",
    "    return float (len(A) / len(number_of_sentences) ) \n",
    "\n",
    "#10 Среднее число слов до подлежащего или сказуемого на предложение\n",
    "def PPos(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    test = sent_tokenize(text)\n",
    "    S = []\n",
    "    for sentence in test:\n",
    "        nlp_sentence = nlp(sentence)\n",
    "        for sent in nlp_sentence.sents:\n",
    "            S += [sent.root.i]\n",
    "  \n",
    "    return float (sum(S) / len(S))\n",
    "\n",
    "#11 Доля «:», «(», «)» и «;» в знаках препинания\n",
    "def PrepR(text):\n",
    "    test = nlp(text)\n",
    "    S = []\n",
    "    for token in test:\n",
    "        if token.pos_ == 'PUNCT':\n",
    "            S.append(token)\n",
    "\n",
    "    semicilons = text.count(';')\n",
    "    colons = text.count(':')\n",
    "    parentheses1 = text.count('(')\n",
    "    parentheses2 = text.count(')')\n",
    "    parentheses = (parentheses1 + parentheses2)/2\n",
    "\n",
    "    total = semicilons + colons + parentheses\n",
    "\n",
    "    return float (total / len(S))\n",
    "\n",
    "#12 Среднее количество слов с пассивным залогом на предложение\n",
    "def PassVerb(text):\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    words = text.split()\n",
    "    res = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'VERB' or p.tag.POS == 'PRTF' or p.tag.POS == 'PRTS':\n",
    "            res.append(p.tag.voice)\n",
    "    S = res.count('pssv')\n",
    "    patternSC = r'ся\\s|сь\\s' #эта досчитывалка регуляркой сделана изз-за кривизны pymorphy2\n",
    "    match_pattern = re.findall(patternSC, text)\n",
    "    total = S + len(match_pattern)\n",
    "    return float ( total / len(number_of_sentences) )  \n",
    "\n",
    "#13 Средняя длина слова в символах\n",
    "def AvWord(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(text)  \n",
    "    text1 = ''.join(e for e in text if e.isalnum())\n",
    "    letters = len(text1)\n",
    "    average_word_length = float(letters / words)\n",
    "    return average_word_length \n",
    "\n",
    "#14 Доля слов текста вне списка A1 + A2\n",
    "def AbsWordAA(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(test)  \n",
    "    test = nlp(test)\n",
    "    lemmatized = []\n",
    "    for token in test:\n",
    "        if token.pos_ != 'PUNCT' and token.pos_ != 'NUM':\n",
    "            lemma = token.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "    S = []\n",
    "    for word in lemmatized:\n",
    "        if word != '':\n",
    "            S.append(word)\n",
    "    S = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in S]\n",
    "    Res = [x for x in S if x not in A1]\n",
    "\n",
    "    return  len(Res) / words\n",
    "\n",
    "#15 Доля слов текста вне списка лексического минимума Минобрнауки B1\n",
    "def AbsWordB(text):\n",
    "    BBB = A1 + B1\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(test)  \n",
    "    test = nlp(test)\n",
    "    lemmatized = []\n",
    "    for token in test:\n",
    "        if token.pos_ != 'PUNCT' and token.pos_ != 'NUM':\n",
    "            lemma = token.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "    S = []\n",
    "    for word in lemmatized:\n",
    "        if word != '':\n",
    "            S.append(word)\n",
    "    S = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in S]\n",
    "    Res = [x for x in S if x not in BBB]\n",
    "\n",
    "    return  len(Res) / words\n",
    "\n",
    "#16 Доля низкочастотных/редких слов\n",
    "def LFW(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    words = test.split()\n",
    "    res = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "    new = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in res]\n",
    "    filtered_tokens = []\n",
    "    for token in new:\n",
    "        if token not in stopwords:\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "\n",
    "    final = [x for x in filtered_tokens if x not in full_dict or x in dictionary_freq]\n",
    "\n",
    "    return len(final) / words1\n",
    "\n",
    "#17 Type token ratio\n",
    "def TTR(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.ttr\n",
    "\n",
    "#18 Root Type-Token Ratio\n",
    "def RootTTR(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.rttr\n",
    "\n",
    "#19 Corrected Type-Token Ratio\n",
    "def CorrTTR(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.cttr\n",
    "\n",
    "#20 Herdan Type-Token Ratio (logarithmic)\n",
    "def HTTR(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.httr\n",
    "\n",
    "\n",
    "#21 Summer Type-Token Ratio\n",
    "def STTR(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.sttr\n",
    "\n",
    "#22 Mean Segmental Type-Token Ratio\n",
    "def MSTTR(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.msttr\n",
    "\n",
    "#23 Measure of Textual Lexical Diversity\n",
    "def MTLD(text):\n",
    "    test = text.lower()\n",
    "    ds = DiversityStats(text)\n",
    "\n",
    "    return ds.mtld\n",
    "\n",
    "#24 Доля слов длиннее 6 символов \n",
    "def Lex6(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(test)  \n",
    "    test = nlp(test)\n",
    "    lemmatized = []\n",
    "    for token in test:\n",
    "        if token.pos_ != 'PUNCT' and token.pos_ != 'NUM':\n",
    "            lemma = token.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "    S = []\n",
    "    for word in lemmatized:\n",
    "        if word != '':\n",
    "            S.append(word)\n",
    "    K = []\n",
    "    for lemma in S:\n",
    "        K.append(len(lemma))\n",
    "    N = []\n",
    "    for number in K:\n",
    "        if number > 6:\n",
    "            N.append(number) \n",
    "    return float (len(N) / words)\n",
    "\n",
    "#25 Доля слов длиннее 8 символов\n",
    "def Lex8(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(test)  \n",
    "    test = nlp(test)\n",
    "    lemmatized = []\n",
    "    for token in test:\n",
    "        if token.pos_ != 'PUNCT' and token.pos_ != 'NUM':\n",
    "            lemma = token.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "    S = []\n",
    "    for word in lemmatized:\n",
    "        if word != '':\n",
    "            S.append(word)\n",
    "    K = []\n",
    "    for lemma in S:\n",
    "        K.append(len(lemma))\n",
    "    N = []\n",
    "    for number in K:\n",
    "        if number > 8:\n",
    "            N.append(number) \n",
    "    return float (len(N) / words)\n",
    "\n",
    "#26 Доля слов длиннее 10 символов\n",
    "def Lex10(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(test)  \n",
    "    test = nlp(test)\n",
    "    lemmatized = []\n",
    "    for token in test:\n",
    "        if token.pos_ != 'PUNCT' and token.pos_ != 'NUM':\n",
    "            lemma = token.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "    S = []\n",
    "    for word in lemmatized:\n",
    "        if word != '':\n",
    "            S.append(word)\n",
    "    K = []\n",
    "    for lemma in S:\n",
    "        K.append(len(lemma))\n",
    "    N = []\n",
    "    for number in K:\n",
    "        if number > 10:\n",
    "            N.append(number) \n",
    "    return float (len(N) / words)\n",
    "\n",
    "#27 Доля слов длиннее 12 символов\n",
    "def Lex12(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(test)  \n",
    "    test = nlp(test)\n",
    "    lemmatized = []\n",
    "    for token in test:\n",
    "        if token.pos_ != 'PUNCT' and token.pos_ != 'NUM':\n",
    "            lemma = token.lemma_.strip()\n",
    "            lemmatized.append(lemma)\n",
    "    S = []\n",
    "    for word in lemmatized:\n",
    "        if word != '':\n",
    "            S.append(word)\n",
    "    K = []\n",
    "    for lemma in S:\n",
    "        K.append(len(lemma))\n",
    "    N = []\n",
    "    for number in K:\n",
    "        if number > 12:\n",
    "            N.append(number) \n",
    "    return float (len(N) / words)\n",
    "\n",
    "#28 Доля отглагольных существительных\n",
    "def VN(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    words = test.split()\n",
    "    res = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "    new = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in res]\n",
    "    S = []\n",
    "    for word in new:\n",
    "        if word.endswith(('тие','ние','ация','аж','ыш','изм','ура','ур','ище','ищ','ство','тва','тель')) or  word in VN1:\n",
    "            S.append(word)\n",
    "    return len(S) / words1\n",
    "\n",
    "#29 Доля существительных в родительном падеже\n",
    "def GenN(text):\n",
    "    test = text.lower()\n",
    "    words = test.split()\n",
    "    nouns = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'NOUN':\n",
    "            nouns.append(p.tag.case)\n",
    "    gents = []\n",
    "    for case in nouns:\n",
    "        if case == 'gent' or case == 'gen2':\n",
    "            gents.append(case)\n",
    "    if len(nouns) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(gents)/len(nouns)\n",
    "    \n",
    "#30 Средняя длина содержательного слова в морфемах\n",
    "def WLM(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    words = test.split()\n",
    "    res = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "    new = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in res]\n",
    "    S = []\n",
    "    for word in new:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'NOUN' or p.tag.POS == 'VERB' or p.tag.POS == 'INFN' or p.tag.POS == 'PRTF' or p.tag.POS == 'PRTS' or p.tag.POS == 'ADVB':\n",
    "            S.append(word)\n",
    "\n",
    "    A = []\n",
    "    M = []\n",
    "    for word in S:\n",
    "        for key, value in Tikh_dict.items():\n",
    "            if key == word:\n",
    "                A.append(Tikh_dict[key])\n",
    "                M.append(word)\n",
    "\n",
    "    return float (sum(A) / len(M))\n",
    "\n",
    "#31 Доля существительных \n",
    "def POSN(text):\n",
    "    test = text.lower()\n",
    "    words = test.split()\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    nouns = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'NOUN':\n",
    "            nouns.append(word)\n",
    "    return float (len(nouns) / words1)\n",
    "\n",
    "#32 Доля глаголов \n",
    "def POSV(text):\n",
    "    test = text.lower()\n",
    "    words = test.split()\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    verbs = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'VERB' or p.tag.POS == 'INFN':\n",
    "            verbs.append(word)\n",
    "    return float (len(verbs) / words1)\n",
    "\n",
    "#33 Доля прилагательных \n",
    "def POSAdj(text):\n",
    "    test = text.lower()\n",
    "    words = test.split()\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    adjectives = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'ADJF' or p.tag.POS == 'ADJS':\n",
    "            adjectives.append(word)\n",
    "    return float (len(adjectives) / words1)\n",
    "\n",
    "#34 Доля наречий \n",
    "def POSA(text):\n",
    "    test = text.lower()\n",
    "    words = test.split()\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    adverbs = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'ADVB':\n",
    "            adverbs.append(word)\n",
    "    return float (len(adverbs) / words1)\n",
    "\n",
    "#35 Доля местоимений \n",
    "def POSPr(text):\n",
    "    test = text.lower()\n",
    "    words = test.split()\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    pronouns = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'NPRO':\n",
    "            pronouns.append(word)\n",
    "    return float (len(pronouns) / words1) \n",
    "\n",
    "#36 Эвфонический индекс по мотивам Индекса Иванова\n",
    "def EuphInd(text):\n",
    "    test = ''.join([i for i in text if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    text1 = ''.join(e for e in test if e.isalnum())\n",
    "    total_letters = len(text1)\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    A = []\n",
    "    for sentence in sentences:\n",
    "        for item in NDU_dict:\n",
    "            if item in sentence:\n",
    "                A.append(item)\n",
    "\n",
    "    S = []\n",
    "    for sentence in sentences:\n",
    "        for item in NDT_dict:\n",
    "            if item in sentence:\n",
    "                S.append(item)\n",
    "\n",
    "    return float ((len(A) + len(S)) / total_letters)\n",
    "\n",
    "#37 Доля абстрактных существительных \n",
    "def AbsN(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    words = test.split()\n",
    "    nouns = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'NOUN':\n",
    "            nouns.append(p.normal_form) \n",
    "\n",
    "    new = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in nouns]\n",
    "    S = []\n",
    "    for word in new:\n",
    "        if word.endswith(('ье','ие','ие','ство','честв','ация','ость','изм','изна','ота','щина','ня','ика','тива')):\n",
    "            S.append(word)\n",
    "\n",
    "    if len(nouns) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float (len(S)/len(nouns))\n",
    "\n",
    "\n",
    "#38 Вес «канцелярита»\n",
    "def Kanz(text):\n",
    "    test = text.lower()\n",
    "    dict_kanz = ('в условиях','в части','в связи','в силу','по мере','за счет','в отношении','на основании','вопреки','ввиду','наподобие','в меру','стороны','наряду','в отличие от','внутри','вокруг','впереди','напротив','поверх','посреди','сверху','свыше','сзади','вслед','наперекор','вопреки','согласно','соответственно','между','помимо','благодаря','включая','исключая','спустя','кончая','не считая','начиная с','несмотря','в заключение','в заключении','по поводу','по причине','в продолжение','в продолжении','по случаю','в соответствии','за счет','за счёт','в течение', 'этих условиях','в настоящее время','на текущий момент','имеет место быть', 'имело место быть','имели место быть','имел место быть','имела место быть','следует отметить','принимая во внимание','гарантированно','в установленном порядке')\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    A = []\n",
    "    for sentence in sentences:\n",
    "        for item in dict_kanz:\n",
    "            if item in sentence:\n",
    "                A.append(item)\n",
    "    \n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    words = test.split()\n",
    "    poses = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        poses.append(p.tag.POS) \n",
    "\n",
    "    mist = []\n",
    "    i = 0\n",
    "    while i < len(poses)-1:\n",
    "        if poses[i] == 'NOUN' and poses[i+1] == 'NOUN':\n",
    "            mist.append('!')\n",
    "            i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    if len(poses) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float ( (2*len(mist) + len(A)) / len(poses)) \n",
    "\n",
    "#39 Вес меток неопределенности \n",
    "def Hedging(text):\n",
    "    test = text.lower()\n",
    "\n",
    "    uncert_tags = ('несколько','немного', 'немногим', 'наверное','вероятно','видимости','возможно','степени','сомнительно','сомнения','сомнение','предположительно','якобы','как утверждают','как утверждается','будто бы','как утверждалось','по утверждениям','слегка','чуть-чуть','незначительно','не в полной мере','неуверенно','может','могло','могла','мог','могли','тем не менее','маловероятно','по-видимому','почти','приблизительно','как бы','на всякий случай','тем не менее','кажется','казаться','казался','представлялся','представляется','казалось','казалась','представлялась','представлялось', 'недооцененный', 'недооценен', 'мера', 'мере', 'мерой', 'меру', 'с учетом', 'с учётом', 'учитывая', 'условиях', 'в том числе', 'по мере', 'неметился', 'намечающийся', 'наметившиеся', 'в целом', 'наряду', 'наряду')\n",
    "\n",
    "    sentences = sent_tokenize(test)\n",
    "    A = []\n",
    "    for sentence in sentences:\n",
    "        for item in uncert_tags:\n",
    "            if item in sentence:\n",
    "                A.append(item)\n",
    "\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "\n",
    "    return float (len(A) / words1)\n",
    "\n",
    "#40 Вес меток «водности» текста (идеально до 15-20%)\n",
    "def WTR(text):\n",
    "    test = text.lower()\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words1 = textstat.lexicon_count(test)  \n",
    "    words = test.split()\n",
    "    res = []\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "\n",
    "    new = [re.sub(u'[Ёё]', u'е', word, flags=re.U|re.I) for word in res]\n",
    "\n",
    "    unfiltered_tokens = []\n",
    "    for token in new:\n",
    "        if token  in stopwords:\n",
    "            unfiltered_tokens.append(token)\n",
    "    \n",
    "    return float (len(unfiltered_tokens) / words1)\n",
    "\n",
    "#41 Вес сущностей\n",
    "def Entit(text):\n",
    "    doc2 = nlp2(text) \n",
    "    S = doc2.entities\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    return float (len(S) / len(sentences))\n",
    "\n",
    "#42 Среднее косинусное расстояние между предложениями\n",
    "def cohLSA(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    i = 0\n",
    "    S = []\n",
    "    for sent in sentences:\n",
    "        while i < len(sentences)-1:\n",
    "            s1 = nlp(sentences[i])\n",
    "            s2 = nlp(sentences[i+1])\n",
    "            s = s1.similarity(s2)\n",
    "            S.append(s)\n",
    "            i += 1\n",
    "\n",
    "    return float (np.mean(S))\n",
    "\n",
    "\n",
    "#43 Адаптированный ARI для экономических текстов на русском языке по шкале от 1 до 10\n",
    "def ARI(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = textstat.lexicon_count(text, removepunct=True)\n",
    "    number_of_sentences = sent_tokenize(text)\n",
    "    sentences = len(number_of_sentences)\n",
    "    average_sentence_length = float(words / sentences)\n",
    "\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c,\"\")\n",
    "    words = textstat.lexicon_count(text)  \n",
    "    text1 = ''.join(e for e in text if e.isalnum())\n",
    "    letters = len(text1)\n",
    "    average_word_length = float(letters / words)\n",
    "    \n",
    "    result = 19.025 - 2.184*average_word_length - 0.048*average_sentence_length\n",
    "    \n",
    "    return result \n",
    "\n",
    "#44 Метки дискурса / асемантические языковые единицы\n",
    "def DiscMar(text):\n",
    "    test = text.lower()\n",
    "\n",
    "    disc_dict = ('буквально','ведь','видишь','видите','в некотором роде','в общем','в общем-то','в принципе','вот','знаешь','знаете','итак','и так далее','как бы','как говорится','как сказать','короче','на самом деле','ну','послушай','правда','прямо','скажем','вообще','собственно говоря','так вот','так сказать','типа','только','то есть','я имею в виду','опять','всего лишь','пожалуй','к счастью','к сожалению','кстати','между прочим','кроме того','также','таким образом','но','однако','хотя','в частности','во-первых','во-вторых','прежде всего','в-третьих','соответственно')\n",
    "\n",
    "    test = ''.join([i for i in test if not i.isdigit()])\n",
    "    for c in string.punctuation:\n",
    "        test = test.replace(c,\"\")\n",
    "    test = test.replace('–', \"\")\n",
    "    test = test.replace('—', \"\")\n",
    "    words = test.split()\n",
    "\n",
    "    R = []  \n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        if p.tag.POS == 'PRCL' or p.tag.POS == 'PRCL':\n",
    "            R.append(word)\n",
    "\n",
    "    L = []\n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        for item in disc_dict:\n",
    "            if item in sentence and item not in S:\n",
    "                L.append(item)\n",
    "    J = L + R\n",
    " \n",
    "    return float(len(J) / len(sentences) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем нейросетевую модель\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim=32, num_heads=2, ff_dim=32, rate=0.1, name = None, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(name=name)\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(TransformerBlock, self).get_config()\n",
    "        config.update({\n",
    "            'num_heads': 2,\n",
    "            'ff_dim': 32,\n",
    "            'embed_dim': 32\n",
    "            })\n",
    "        return config\n",
    "\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen=300, vocab_size=40000, embed_dim=32, name = None, **kwargs):\n",
    "        super(TokenAndPositionEmbedding, self).__init__(name=name)\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "        super(TokenAndPositionEmbedding, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'vocab_size': 40000,\n",
    "            'maxlen': 300,\n",
    "            'embed_dim': 32\n",
    "            })\n",
    "        return config\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "\n",
    "#загружаем словарь \n",
    "with open('tokenizer13.json') as f:\n",
    "    data = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(data)\n",
    "\n",
    "#загружаем саму модель\n",
    "model = tf.keras.models.load_model('NN_model_May21.h5', custom_objects= {'TokenAndPositionEmbedding': TokenAndPositionEmbedding, 'TransformerBlock': TransformerBlock})\n",
    "\n",
    "nb_classes = 10\n",
    "maxlen = 300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка текста для обработки\n",
    "\n",
    "Testing_text = open(\"test.txt\", 'r')\n",
    "Testing_text = Testing_text.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Обработка текста\n",
    "\n",
    "data = {'Text': [Testing_text], 'SenLen': SenLen(Testing_text), 'PTH': PTH(Testing_text),'SubCon': SubCon(Testing_text),'CoordC': CoordC(Testing_text),'NP': NP(Testing_text),'VP': VP(Testing_text),\n",
    "'NUM': NUM(Testing_text),'DiffSynt': DiffSynt(Testing_text),'LSDaoust': LSDaoust(Testing_text),'PPos': PPos(Testing_text),'PrepR': PrepR(Testing_text),'PassVerb': PassVerb(Testing_text),'AvWord': AvWord(Testing_text),\n",
    "'AbsWordAA': AbsWordAA(Testing_text),'AbsWordB': AbsWordB(Testing_text),'LFW': LFW(Testing_text),'TTR': TTR(Testing_text),'RootTTR': RootTTR(Testing_text),'CorrTTR': CorrTTR(Testing_text),'HTTR': HTTR(Testing_text),\n",
    "'STTR': STTR(Testing_text),'MSTTR': MSTTR(Testing_text),'MTLD': MTLD(Testing_text),'Lex6': Lex6(Testing_text),'Lex8': Lex8(Testing_text),'Lex10': Lex10(Testing_text),'Lex12': Lex12(Testing_text),\n",
    "'VN': VN(Testing_text),'GenN': GenN(Testing_text),'WLM': WLM(Testing_text),'POSN': POSN(Testing_text),'POSV': POSV(Testing_text),'POSAdj': POSAdj(Testing_text),\n",
    "'POSA': POSA(Testing_text),'POSPr': POSPr(Testing_text),'EuphInd': EuphInd(Testing_text),'AbsN': AbsN(Testing_text),'Kanz': Kanz(Testing_text),'Hedging': Hedging(Testing_text),'WTR': WTR(Testing_text),\n",
    "'Entit': Entit(Testing_text),'cohLSA': cohLSA(Testing_text),'ARI': ARI(Testing_text),'DiscMar': DiscMar(Testing_text)}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\379\\sklearn\\base.py:444: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "#Оценка текста нейросетевой моделью \n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(df['Text'])\n",
    "x_val = pad_sequences(test_sequences, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
    "\n",
    "test_df = df.drop('Text', axis=1)\n",
    "\n",
    "X_test_scaled = ss.transform(test_df)\n",
    "\n",
    "X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict([x_val, X_test_scaled])\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)+1\n",
    "\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//Оптимальное значение удобочитаемости - выше 6. Такой текст доступен большей части населения.//\n",
      "\n",
      "Метрики вашего текста:\n",
      "4.60862284014189 - Классическая оценка удобочитаемости на основе средней длины слов и предложений\n",
      "Ваш текст доступен учащимся вузов, а также людям со средним специальным образованием\n",
      "2 - Удобочитаемость, оценка нейросетевой модели\n",
      "Ваш текст доступен магистрам, аспирантам экономических специальностей\n",
      "\n",
      "///Отдельные характеристики текста, улучшение которых позволит повысить удобочитаемость///\n",
      "Из них топ-7 важнейших:\n",
      "1. Средняя длина слова в символах: 6.200823892893924 //Оптимально (среднее значение для 6го уровня) < 5.98365741523809\n",
      "2. Средняя длина предложения в словах: 18.203703703703702 //Оптимально < 16.02344739873717\n",
      "3. Доля существительных: 0.2517802644964395 //Оптимально < 0.25078608578531747\n",
      "4. Доля слов длиннее 8 символов: 0.25798146240988673 //Оптимально < 0.22357996388384185\n",
      "5. Доля отглагольных существительных: 0.08770108977685522 //Оптимально < 0.0716975295562396\n",
      "6. Среднее количество слов с пассивным залогом или возвратной формой на предложение: 0.5 //Оптимально < 0.5294425959430092\n",
      "7. Среднее число предложений, отягощенных причастиями и деепричастиями: 0.23148148148148148 //Оптимально < 0.32258362278746855\n",
      "\n",
      "Прочие:\n",
      "Средняя длина дерева синтаксического разбора на предложение: 5.724137931034483 //Оптимально < 5.392461876298687\n",
      "Среднее число подчинительных союзов на предложение: 0.2777777777777778 //Оптимально < 0.24590303381930237\n",
      "Среднее число сочинительных союзов на предложение: 0.4351851851851852 //Оптимально < 0.22826876067946722\n",
      "Доля именных деревьев в среднем на предложение: 0.1388888888888889 //Оптимально < 0.07225599758247445\n",
      "Доля глагольных деревьев в среднем на предложение: 0.7222222222222222 //Оптимально > 0.7942089845265379\n",
      "Среднее число цифр на предложение: 0.24074074074074073 //Оптимально < 0.29722749684907984\n",
      "Доля предложений, длина которых превышает 25 слов: 0.17592592592592593 //Оптимально < 0.1459197808822559\n",
      "Среднее число слов до подлежащего или сказуемого на предложение: 5.706422018348624 //Оптимально < 5.181730529685941\n",
      "Доля «:», «(», «)» и «;» в знаках препинания: 0.01948051948051948 //Оптимально < 0.031730535428459515\n",
      "Доля слов текста вне списка лексического минимума Минобрнауки A2 (базовый): 0.5535530381050463 //Оптимально < 0.5219993459811691\n",
      "Доля слов текста вне списка лексического минимума Минобрнауки B1 (первый сертификационный уровень): 0.46138002059732236 //Оптимально < 0.43205610636445063\n",
      "Доля низкочастотных слов (условно терминов): 0.04151530877010898 //Оптимально < 0.10336615931506997\n",
      "Лексическое разнообразие 1: 0.5195530726256983 //Оптимально > 0.7540145922582578\n",
      "Лексическое разнообразие 2: 23.054344347564722 //Оптимально > 11.55135020226921\n",
      "Лексическое разнообразие 3: 16.301883223972766 //Оптимально > 8.168038059885133\n",
      "Лексическое разнообразие по формуле Herdan: 0.9136767239210898 //Оптимально > 0.9479673799357601\n",
      "Лексическое разнообразие по формуле Somers: 0.924274292435061 //Оптимально > 0.9377959894865681\n",
      "Модификация метрики TTR с использованием сегментирования: 0.8897435897435896 //Оптимально > 0.8986683355803643\n",
      "Лексическое разнообразие по формуле McCarthy and Jarvis: 286.66508988424437 //Оптимально > 262.3759935124898\n",
      "Доля слов длиннее 6 символов: 0.417610710607621 //Оптимально < 0.4110677383813233\n",
      "Доля слов длиннее 10 символов: 0.12100926879505665 //Оптимально < 0.10218454534254123\n",
      "Доля слов длиннее 12 символов: 0.04737384140061792 //Оптимально < 0.03922159561975452\n",
      "Нагруженность канцеляритом: 0.19719771665801764 //Оптимально < 0.22059938451417027\n",
      "Доля существительных в родительном падеже: 0.4 //Оптимально < 0.3535513977365723\n",
      "Средняя длина содержательного слова  в морфемах: 1.9242424242424243 //Оптимально < 1.971563864653573\n",
      "Доля глаголов: 0.09562563580874874 //Оптимально > 0.10463763007050884\n",
      "Доля прилагательных: 0.15971515768056968 //Оптимально ~ 0.1212542934468348\n",
      "Доля наречий: 0.04069175991861648 //Оптимально ~ 0.038119436988495584\n",
      "Доля местоимений: 0.028484231943031537 //Оптимально ~ 0.033903158016570595\n",
      "Эвфонический индекс на основе Иванов (2013): 0.16052150805514034 //Оптимально > 0.16430284019519137\n",
      "Доля абстрактных существительных: 0.30434782608695654 //Оптимально < 0.18424762356036078\n",
      "Вес меток неопределенности: 0.022314478463933574 //Оптимально < 0.011028098947534001\n",
      "Вес меток «водности» текста (стоп-слова, не несущие содержательного смысла): 0.4244940321743643 //Оптимально ~ 0.4213621630589011\n",
      "Плотность сущностей (entities), или устойчивых понятий в тексте: 0.21296296296296297 //Оптимально < 1.0498635118245612\n",
      "Связность предложений внутри текста: 0.5859257842253786 //Оптимально > 0.5291031318188171\n",
      "Метки разговорного стиля: 1.6944444444444444 //Оптимально > 1.3044459743870107\n",
      "\n",
      "Подробная информация о моделях и характеристиках текста представлена в Evstigneeva, A. and Sidorovskiy, M. (2021). Assessment of Clarity of Bank of Russia Monetary Policy Communication by Neural Network Approach. Russian Journal of Money and Finance, 80(3), pp. 3–33. doi: 10.31477/rjmf.202103.03\n"
     ]
    }
   ],
   "source": [
    "#Вывод итоговых результатов оценки текста\n",
    "\n",
    "print(\"//Оптимальное значение удобочитаемости - выше 6. Такой текст доступен большей части населения.//\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Метрики вашего текста (целевой уровень - 5-6)\")\n",
    "\n",
    "print('ЯСНОСТЬ ФОРМЫ (Классическая оценка удобочитаемости на основе средней длины слов и предложений):', ARI(Testing_text))\n",
    "\n",
    "x = round(ARI(Testing_text))\n",
    "\n",
    "if x <= 1:\n",
    "    print(\"Ваш текст доступен\", \"докторам экономических наук\")\n",
    "elif x == 2:\n",
    "    print(\"Ваш текст доступен\", \"магистрам, аспирантам экономических специальностей\")\n",
    "elif x == 3:\n",
    "    print(\"Ваш текст доступен\", \"выпускникам вузов экономических специальностей\")  \n",
    "elif x == 4:\n",
    "    print(\"Ваш текст доступен\", \"выпускникам вузов неэкономических специальностей\") \n",
    "elif x == 5:\n",
    "    print(\"Ваш текст доступен\", \"учащимся вузов, а также людям со средним специальным образованием\")   \n",
    "elif x == 6:\n",
    "    print(\"Ваш текст доступен\", \"выпускникам школ\")   \n",
    "elif x == 7:\n",
    "    print(\"Ваш текст доступен\", \"учащимся старших классов\")\n",
    "elif x == 8:\n",
    "    print(\"Ваш текст доступен\", \"учащимся старших средних классов\")\n",
    "elif x == 9:\n",
    "    print(\"Ваш текст доступен\", \"учащимся младших средних классов\")\n",
    "elif x > 10:\n",
    "    print(\"Ваш текст доступен\", \"младшим школьникам\")         \n",
    "\n",
    "\n",
    "print('ЯСНОСТЬ СОДЕРЖАНИЯ (классификатор нейронной сети):', int(y_pred))\n",
    "\n",
    "x = int(y_pred)\n",
    "\n",
    "if x <= 1:\n",
    "    print(\"Ваш текст доступен\", \"докторам экономических наук\")\n",
    "elif x == 2:\n",
    "    print(\"Ваш текст доступен\", \"магистрам, аспирантам экономических специальностей\")\n",
    "elif x == 3:\n",
    "    print(\"Ваш текст доступен\", \"выпускникам вузов экономических специальностей\")  \n",
    "elif x == 4:\n",
    "    print(\"Ваш текст доступен\", \"выпускникам вузов неэкономических специальностей\") \n",
    "elif x == 5:\n",
    "    print(\"Ваш текст доступен\", \"учащимся вузов, а также людям со средним специальным образованием\")   \n",
    "elif x == 6:\n",
    "    print(\"Ваш текст доступен\", \"выпускникам школ\")   \n",
    "elif x == 7:\n",
    "    print(\"Ваш текст доступен\", \"учащимся старших классов\")\n",
    "elif x == 8:\n",
    "    print(\"Ваш текст доступен\", \"учащимся старших средних классов\")\n",
    "elif x == 9:\n",
    "    print(\"Ваш текст доступен\", \"учащимся младших средних классов\")\n",
    "elif x > 10:\n",
    "    print(\"Ваш текст доступен\", \"младшим школьникам\")     \n",
    "\n",
    "print()\n",
    "\n",
    "print(\"///Отдельные характеристики текста, улучшение которых позволит повысить удобочитаемость///\")\n",
    "\n",
    "print(\"Из них топ-7 важнейших:\")\n",
    "print(\"1. Средняя длина слова в символах:\", df.AvWord[0], \"//Оптимально (среднее значение для 6го уровня) < 5.98365741523809\")\n",
    "print(\"2. Средняя длина предложения в словах:\", df.SenLen[0], \"//Оптимально < 16.02344739873717\")\n",
    "print(\"3. Доля существительных:\", df.POSN[0], \"//Оптимально < 0.25078608578531747\")\n",
    "print(\"4. Доля слов длиннее 8 символов:\", df.Lex8[0], \"//Оптимально < 0.22357996388384185\")\n",
    "print(\"5. Доля отглагольных существительных:\", df.VN[0], \"//Оптимально < 0.0716975295562396\")\n",
    "print(\"6. Среднее количество слов с пассивным залогом или возвратной формой на предложение:\", df.PassVerb[0], \"//Оптимально < 0.5294425959430092\")\n",
    "print(\"7. Среднее число предложений, отягощенных причастиями и деепричастиями:\", df.DiffSynt[0], \"//Оптимально < 0.32258362278746855\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Прочие:\")\n",
    "print(\"Средняя длина дерева синтаксического разбора на предложение:\", df.PTH[0], \"//Оптимально < 5.392461876298687\")\n",
    "print(\"Среднее число подчинительных союзов на предложение:\", df.SubCon[0], \"//Оптимально < 0.24590303381930237\")\n",
    "print(\"Среднее число сочинительных союзов на предложение:\", df.CoordC[0], \"//Оптимально < 0.22826876067946722\")\n",
    "print(\"Доля именных деревьев в среднем на предложение:\", df.NP[0], \"//Оптимально < 0.07225599758247445\")\n",
    "print(\"Доля глагольных деревьев в среднем на предложение:\", df.VP[0], \"//Оптимально > 0.7942089845265379\")\n",
    "print(\"Среднее число цифр на предложение:\", df.NUM[0], \"//Оптимально < 0.29722749684907984\")\n",
    "print(\"Доля предложений, длина которых превышает 25 слов:\", df.LSDaoust[0], \"//Оптимально < 0.1459197808822559\")\n",
    "print(\"Среднее число слов до подлежащего или сказуемого на предложение:\", df.PPos[0], \"//Оптимально < 5.181730529685941\")\n",
    "print(\"Доля «:», «(», «)» и «;» в знаках препинания:\", df.PrepR[0], \"//Оптимально < 0.031730535428459515\")\n",
    "print(\"Доля слов текста вне списка лексического минимума Минобрнауки A2 (базовый):\", df.AbsWordAA[0], \"//Оптимально < 0.5219993459811691\")\n",
    "print(\"Доля слов текста вне списка лексического минимума Минобрнауки B1 (первый сертификационный уровень):\", df.AbsWordB[0], \"//Оптимально < 0.43205610636445063\")\n",
    "print(\"Доля низкочастотных слов (условно терминов):\", df.LFW[0], \"//Оптимально < 0.10336615931506997\")\n",
    "print(\"Лексическое разнообразие 1:\", df.TTR[0], \"//Оптимально > 0.7540145922582578\")\n",
    "print(\"Лексическое разнообразие 2:\", df.RootTTR[0], \"//Оптимально > 11.55135020226921\")\n",
    "print(\"Лексическое разнообразие 3:\", df.CorrTTR[0], \"//Оптимально > 8.168038059885133\")\n",
    "print(\"Лексическое разнообразие по формуле Herdan:\", df.HTTR[0], \"//Оптимально > 0.9479673799357601\")\n",
    "print(\"Лексическое разнообразие по формуле Somers:\", df.STTR[0], \"//Оптимально > 0.9377959894865681\")\n",
    "print(\"Модификация метрики TTR с использованием сегментирования:\", df.MSTTR[0], \"//Оптимально > 0.8986683355803643\")\n",
    "print(\"Лексическое разнообразие по формуле McCarthy and Jarvis:\", df.MTLD[0], \"//Оптимально > 262.3759935124898\")\n",
    "print(\"Доля слов длиннее 6 символов:\", df.Lex6[0], \"//Оптимально < 0.4110677383813233\")\n",
    "print(\"Доля слов длиннее 10 символов:\", df.Lex10[0], \"//Оптимально < 0.10218454534254123\")\n",
    "print(\"Доля слов длиннее 12 символов:\", df.Lex12[0], \"//Оптимально < 0.03922159561975452\")\n",
    "print(\"Нагруженность канцеляритом:\", df.Kanz[0], \"//Оптимально < 0.22059938451417027\")\n",
    "print(\"Доля существительных в родительном падеже:\", df.GenN[0], \"//Оптимально < 0.3535513977365723\")\n",
    "print(\"Средняя длина содержательного слова  в морфемах:\", df.WLM[0], \"//Оптимально < 1.971563864653573\")\n",
    "print(\"Доля глаголов:\", df.POSV[0], \"//Оптимально > 0.10463763007050884\")\n",
    "print(\"Доля прилагательных:\", df.POSAdj[0], \"//Оптимально ~ 0.1212542934468348\")\n",
    "print(\"Доля наречий:\", df.POSA[0], \"//Оптимально ~ 0.038119436988495584\")\n",
    "print(\"Доля местоимений:\", df.POSPr[0], \"//Оптимально ~ 0.033903158016570595\")\n",
    "print(\"Эвфонический индекс на основе Иванов (2013):\", df.EuphInd[0], \"//Оптимально > 0.16430284019519137\")\n",
    "print(\"Доля абстрактных существительных:\", df.AbsN[0], \"//Оптимально < 0.18424762356036078\")\n",
    "print(\"Вес меток неопределенности:\", df.Hedging[0], \"//Оптимально < 0.011028098947534001\")\n",
    "print(\"Вес меток «водности» текста (стоп-слова, не несущие содержательного смысла):\", df.WTR[0], \"//Оптимально ~ 0.4213621630589011\")\n",
    "print(\"Плотность сущностей (entities), или устойчивых понятий в тексте:\", df.Entit[0], \"//Оптимально < 1.0498635118245612\")\n",
    "print(\"Связность предложений внутри текста:\", df.cohLSA[0], \"//Оптимально > 0.5291031318188171\")\n",
    "print(\"Метки разговорного стиля:\", df.DiscMar[0], \"//Оптимально > 1.3044459743870107\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Подробная информация о моделях и характеристиках текста представлена в Evstigneeva, A. and Sidorovskiy, M. (2021). Assessment of Clarity of Bank of Russia Monetary Policy Communication by Neural Network Approach. Russian Journal of Money and Finance, 80(3), pp. 3–33.\",\n",
    "\"doi: 10.31477/rjmf.202103.03\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd5567b1dcfb899d08862ae1b0194f383bedba8a1f29537370c3019d28c1e2bd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
